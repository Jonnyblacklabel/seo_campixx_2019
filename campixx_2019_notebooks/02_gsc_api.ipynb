{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Google Search Console API\n",
    "In diesem Notebook:\n",
    "- Abfrage der Google Search Console API.\n",
    "- Eigentlich aufw√§ndiger, dank des Package [\"searchconsole\"](https://github.com/joshcarty/google-searchconsole) stark vereinfacht. (Josh Carty)\n",
    "- Simple Authentifizierung des Google Accounts, ebenfalls dank dieses Package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zuerst ben√∂tigt ihr ein Projekt in der Google Cloud\n",
    "‚Üí https://console.cloud.google.com/home/dashboard\n",
    "\n",
    "![api keys](data/g_api_key.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentifizierung\n",
    "Wenn ihr die `client_secret.json` Datei abgespeichert habt, k√∂nnt ihr sie in der `.authenticate` Funktion angeben.\n",
    "```python\n",
    "# Authentifizierung\n",
    "searchconsole.authenticate(client_config='client_secret.json')\n",
    "\n",
    "# Authentifizierung & Speichern der Credentials\n",
    "searchconsole.authenticate(client_config='client_secret.json', serialize='path/to/cred_file')\n",
    "\n",
    "# Authentifizierung mit Credentials\n",
    "searchconsole.authenticate(client_config='client_secret.json', credentials='path/to/cred_file')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import searchconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = searchconsole.authenticate(client_config='client_secret.json', credentials='credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webproperty = account['https://www.serienjunkies.de/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abfragen\n",
    "Die Abfragen k√∂nnen mittels `method-chaining` an `webproperty.query` angef√ºgt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = webproperty.query.range('today', days=-7).dimension('date').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.rows[0].date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in report.rows:\n",
    "    print(f'{row.date} - clicks [{row.clicks}] - impressions [{row.impressions}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aber wir wollen ja mit DataFrames arbeiten. \n",
    "# üöÄ Go Pandas, go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 33:38 helpers/helpers.py\n",
    "sns.set(context='talk',\n",
    "        rc={'figure.figsize':(15,6),\n",
    "            'axes.titlepad':18,\n",
    "            'axes.titlesize':22,\n",
    "            'figure.constrained_layout.use':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abfrage f√ºr alle Monate\n",
    "Dank des Package kann mittels `.range('today', months=-16)` sehr simple ein gr√∂√üerer Umfang heruntergeladen werden. Dabei werden alle paginierten Seiten der API geladen. Mittels der Funktion `.to_dataframe()` wird das Ergebnis der API direkt in einen DataFrame √ºberf√ºhrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = webproperty.query.range('today', months=-16).dimension('date').get()\n",
    "df_totals = report.to_dataframe()\n",
    "df_totals['date'] = pd.to_datetime(df_totals['date'])\n",
    "df_totals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abfrage mit mehreren Dimensionen\n",
    "Auch die Kombination von Dimensionen ist einfach. Alle zugelassenen Kombinationen werden so angegeben `.dimension('date','page','query')`. \n",
    "\n",
    "**Achtung:** `searchAppearance` kann mit keiner anderen Dimension kombiniert werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = webproperty.query.range('today', months=-1).dimension('searchAppearance').get().to_dataframe()\n",
    "sa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = webproperty.query.range('today', days=-9).dimension('date','page','query').get().to_dataframe()\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeit f√ºr einen ersten Plot\n",
    "In den Beispielen haben wir einmal die Gesamtwerte erfasst, aber auch die Daten mit Suchanfragen und Seiten. Zeigen wir beide Zeitverl√§ufe in einer Grafik wird deutlich, dass die Summen (wie wir ja alle schon l√§nger wissen) der Daten die Suchanfragen und Seiten enthalten, niemals die Gesamtwerte ergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_totals.query('date >= @df.date.min()').groupby('date')['clicks'].sum().plot(label='totals')\n",
    "ax = df.groupby('date')['clicks'].sum().plot(label='page&query', ax=ax)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinzuf√ºgen weiterer Features\n",
    "Im Laufe einer Analyse ist es so gut wie immer n√∂tig, weitere Spalten an das Datenset anzuf√ºgen. Das kann nat√ºrlich ein anderes Datenset sein, welches mittels `.join` [(link)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) oder `.merge` [(link)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) angef√ºgt wird. In unserem einfachen Beispiel errechnen wir aus den Daten eine `brand`-Spalte und eine `word_count`-Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'] = df['query'].str.contains('serienjunkies')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die %%timeit cell-magic\n",
    "Neben anderen n√ºtzlichen `cell-magic` Funktionen, k√∂nnt ihr mit `%%timeit` testen, wie schnell euer Code ausgef√ºht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df['word_count'] = df['query'].str.split(r'\\s').str.len().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df['word_count'] = [len(x.split(r'\\s')) for x in df['query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df['word_count'] = df['query'].str.count(r'\\s') +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots mit neuen Features\n",
    "Mit dem aktuellen DataFrame werden wir nun folgende Plots erstellen:\n",
    "- Zeitverlauf mit Brand und Nonbrand\n",
    "- Ein Histogram der Seiten f√ºr Klicks\n",
    "- Einen Stripplot der Klicks verteilt auf die Anzahl der W√∂rter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['date','brand'], as_index=False)['clicks'].sum() \\\n",
    "    .pipe((sns.lineplot, 'data'), x='date', y='clicks', hue='brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.query('(clicks > 100) and ~(page.isin([\"https://www.serienjunkies.de/\"]))') \\\n",
    "    .groupby('page')[['clicks']].sum() \\\n",
    "    .pipe(sns.distplot, kde=False)\n",
    "ax.set_xlabel('Klicks')\n",
    "ax.set_ylabel('Frequenz')\n",
    "# .query('(clicks > 100) and ~(page.isin([\"https://www.serienjunkies.de/\"]))') \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('page')[['clicks']].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('brand == False and page != \"https://www.serienjunkies.de/\"') \\\n",
    "    .groupby(['word_count', 'query'], as_index=False).sum() \\\n",
    "    .pipe((sns.stripplot, 'data'), x='word_count', y='clicks')\n",
    "\n",
    "# .query('brand == False and page != \"https://www.serienjunkies.de/\"') \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abspeichern mit Dataset\n",
    "Die geladenen Daten k√∂nnen nat√ºrlich auch abgespeichert werden. Eine Datenbank ist da immer sinnvoll. In unseren simplen Beispielen werden wir mit einer einfachen Sqlite arbeiten. Um es noch einfacher zu machen, verwenden wir das Package `dataset` [(link)](https://dataset.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dataset.connect('sqlite:///data/campixx_sa.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('searchanalytics_data', con=db.engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Datein, Excel und weitere Formate sind nat√ºrlich m√∂glich.\n",
    "Alle Funktionen f√ºr Input / Output gibt's [hier](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)\n",
    "```python\n",
    "# csv\n",
    "df.to_csv('data/searchanalytics_data.csv')\n",
    "# excel\n",
    "df.to_excel(...)\n",
    "# google big query\n",
    "df.to_gbq(...)\n",
    "# viele weitere\n",
    "df.to + Tab dr√ºcken!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchanalytics Daten speichern\n",
    "Da die Daten der GSC auf 16 Monate beschr√§nkt sind, macht es durchaus Sinn sie abzuspeichern. F√ºr alle **SEOs** ist das zumindest eine **Pflicht**. Wie wir eben gesehen haben, ist das eigentlich nicht so schwierig. \n",
    "Um die Daten in gr√∂√üerem Umfang zu speichern, muss man allerdings mindestens folgendes tun:\n",
    "- Die Daten m√ºssen f√ºr jeden Tag einzeln abgefragt werden. *(jeder Tag = eine Abfrage)*\n",
    "    - Pro Tag k√∂nnen maximal 50.000 Zeilen in der Antwort enthalten sein.\n",
    "- Die Abfragen m√ºssen f√ºr die m√∂glichen Kombinationen der Dimensionen durchgef√ºhrt werden. *[country, device, page, query]*\n",
    "    - Wir haben ja festgestellt, dass die Mengen sich je nach Dimensionen unterscheiden.\n",
    "- Wenn ich die Daten zur searchAppearance haben m√∂chte, muss ich √ºber alle m√∂glichen Filter iterieren.\n",
    "    - searchAppearance kann mit keiner anderen Dimension kombiniert werden.\n",
    "- F√ºr verschiedene Google Accounts, muss ich mehrere Auth-Files speichern und den Abfragen zuweisen.\n",
    "- Man muss sich merken, welche Tage bereits abgefragt wurden und welche nicht.\n",
    "    - Wenn w√§hrend der Abfrage die API nicht mehr antwortet, muss man von neuem anfangen.\n",
    "- Man sollte ebenfalls pr√ºfen, an welchen Tagen Daten vorliegen, um die API quotas nicht zu verschwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also wie immer:** *\"mal eben schnell\"* ist **immer** weder *mal eben*, noch *schnell*...\n",
    "\n",
    "![mal eben schnell scripten](data/mal_eben.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F√ºr die Campixx hab ich daher was gebaut\n",
    "**Disclaimer:** Nur f√ºr diejenigen, die es nicht selbst k√∂nnen. \n",
    "- Daten werden \"nur\" in eine lokale Sqlite gespeichert\n",
    "- Daten werden nicht normalisiert\n",
    "- Zum arbeiten (32 GB Daten) hat alles gut funktioniert üòù\n",
    "\n",
    "‚Üí [gsc-sa-downloader auf GitHub](https://github.com/Jonnyblacklabel/gsc_sa_downloader)\n",
    "\n",
    "## So geht's\n",
    "Readme auf GitHub lesen und den Anweisungen zur Installation folgen.\n",
    "\n",
    "## Ihr habt `pipenv install` ausgef√ºhrt?\n",
    "Alles weitere l√§uft per CLI. Also √∂ffnet eine `cmd` (oder PowerShell, Terminal, etc...) in dem Ordner in den ihr alles kopiert habt.\n",
    "```\n",
    "# Download der GSC Daten f√ºr eure Property\n",
    "pipenv shell\n",
    "cd gsc_sa_downloader\n",
    "python gsc_sa_downloader.py download [account name] [property mit trailing slash \"/\"] --generate\n",
    "```\n",
    "Da der Account verifiziert werden muss, kommt der √ºbliche Prozess in eurem Browser.\n",
    "Danach sollte es auch schon losgehen. Ich hoffe es funktioniert üòè"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
